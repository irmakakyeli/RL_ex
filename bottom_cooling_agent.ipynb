{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab18b53-0928-443f-a404-3e5b20360a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\irmak\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.1.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.6.0+cu118)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.9.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pygame in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.19.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.66.5)\n",
      "Requirement already satisfied: rich in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.7.1)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.10.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (10.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef81a58-2ba5-4d87-bfd7-939298550236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'boptestGymService'...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  !rm -rf boptestGymService\n",
    "except:\n",
    "  pass\n",
    "!git clone -b boptest-gym-service https://github.com/ibpsa/project1-boptest-gym.git boptestGymService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc34e91-15b8-45a2-bda8-56b49143534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7beb85d8-902a-49ca-bea5-754ab2918d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'boptestGymService')\n",
    "\n",
    "url = 'https://api.boptest.net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f44b54-02f9-4bde-85d0-bf2407f849c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irmak\\Documents\\GitHub\\RL_ex\\boptestGymService\\examples\\test_and_plot.py:122: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  axs[0].set_ylabel('Operative\\ntemperature\\n($^\\circ$C)')\n",
      "C:\\Users\\irmak\\Documents\\GitHub\\RL_ex\\boptestGymService\\examples\\test_and_plot.py:131: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  axs[3].set_ylabel('Ambient\\ntemperature\\n($^\\circ$C)')\n",
      "C:\\Users\\irmak\\Documents\\GitHub\\RL_ex\\boptestGymService\\examples\\test_and_plot.py:135: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  axt.plot(x_time, df['weaSta_reaWeaHDirNor_y'], color='gold', linestyle='-', linewidth=1, label='$\\dot{Q}_rad$')\n",
      "C:\\Users\\irmak\\Documents\\GitHub\\RL_ex\\boptestGymService\\examples\\test_and_plot.py:141: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  axs[3].plot([],[], color='gold',        linestyle='-', linewidth=1, label='$\\dot{Q}_{rad}$')\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from boptestGymService.boptestGymEnv import BoptestGymEnv\n",
    "from boptestGymEnv import DiscretizedActionWrapper\n",
    "from gym.wrappers import FlattenObservation\n",
    "from boptestGymEnv import DiscretizedObservationWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92427732-c230-43fa-b9bf-4c3871394b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine reward function\n",
    "class BoptestGymEnvCustomReward(BoptestGymEnv):\n",
    "    '''Define a custom reward for this building\n",
    "\n",
    "    '''\n",
    "    def get_reward(self):\n",
    "        '''Custom reward function. To expedite learning, we use a clipped reward\n",
    "        function that has a value of 1 when there is no increase in discomfort\n",
    "        and 0 otherwise. We use the BOPTEST `GET /kpis` API call to compute the\n",
    "        total cummulative discomfort from the beginning of the episode. Note\n",
    "        that this is the true value that BOPTEST uses when evaluating\n",
    "        controllers.\n",
    "\n",
    "        '''\n",
    "        # Compute BOPTEST core kpis\n",
    "        kpis = requests.get('{0}/kpi/{1}'.format(self.url, self.testid)).json()['payload']\n",
    "        # Calculate objective integrand function as the total discomfort\n",
    "        objective_integrand = kpis['tdis_tot']\n",
    "        # Give reward if there is not immediate increment in discomfort\n",
    "        if objective_integrand == self.objective_integrand:\n",
    "          reward=1\n",
    "        else:\n",
    "          reward=0\n",
    "        # Record current objective integrand for next evaluation\n",
    "        self.objective_integrand = objective_integrand\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226d1fa-730d-4e26-ae2a-529cad9ecfab",
   "metadata": {},
   "source": [
    "##KPIs##\n",
    "\n",
    "Thermal discomfort: reported with units of [ Kh/zone ], defines the cumulative deviation of zone temperatures from upper and lower comfort limits that are predefined within the test case FMU for each zone, averaged over all zones. Air temperature is used for air-based systems and operative temperature is used for radiant systems.\n",
    "\n",
    "Indoor Air Quality (IAQ) Discomfort: reported with units of [ ppmh/zone ], defines the extent that the CO 2  concentration levels in zones exceed bounds of the acceptable concentration level, which are predefined within the test case FMU for each zone, averaged over all zones.\n",
    "\n",
    "Energy Use: reported with units of [ kWh/m2 ], defines the HVAC energy usage.\n",
    "\n",
    "Peak electrical demand:reported with units of [ kW/m2 ], defines the HVAC peak electrical demand.\n",
    "\n",
    "Peak gas demand:reported with units of [ kW/m2 ], defines the HVAC peak gas demand.\n",
    "\n",
    "Peak district heating demand:reported with units of [ kW/m2 ], defines the HVAC peak district heating demand.\n",
    "\n",
    "Cost: reported with units of [USD/ m2 ] or [EUR/ m2 ], defines the operational cost associated with the HVAC energy usage.\n",
    "\n",
    "Emissions: reported with units of [ kgCO2/m2 ], defines the  CO2  emissions from the HVAC energy usage.\n",
    "\n",
    "Computational time ratio: defines the average ratio between the controller computation time and the test simulation control step. The controller computation time is measured as the time between two emulator advances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5eed2f-ea18-4051-9918-2d35c7d0b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case=\"multizone_office_simple_air\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f85ae6c-5d89-4e71-a31f-6bcb0b287b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mBoptestGymEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'http://127.0.0.1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtestcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bestest_hydronic_heat_pump'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'oveHeaPumY_u'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobservations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'reaTZon_y'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m280.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m310.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reward'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_episode_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_start_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexcluding_periods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mregressive_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpredictive_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstart_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarmup_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mscenario\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'electricity_price'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'constant'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstep_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrender_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:\\\\Users\\\\irmak\\\\Documents\\\\GitHub\\\\RL_ex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "BOPTEST Environment that follows gym interface.\n",
       "This environment allows the interaction of RL agents with building\n",
       "emulator models from BOPTEST. \n",
       " \n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "url: string\n",
       "    Rest API url for communication with the BOPTEST interface\n",
       "testcase: string\n",
       "    The string identifier of the testcase\n",
       "actions: list\n",
       "    List of strings indicating the action space. The bounds of \n",
       "    each variable from the action space the are retrieved from \n",
       "    the overwrite block attributes of the BOPTEST test case\n",
       "observations: dictionary\n",
       "    Dictionary mapping observation keys to a tuple with the lower\n",
       "    and upper bound of each observation. Observation keys must \n",
       "    belong either to the set of measurements or to the set of \n",
       "    forecasting variables of the BOPTEST test case. Contrary to \n",
       "    the actions, the expected minimum and maximum values of the \n",
       "    measurement and forecasting variables are not provided from \n",
       "    the BOPTEST framework, although they are still relevant here \n",
       "    e.g. for normalization or discretization. Therefore, these \n",
       "    bounds need to be provided by the user. \n",
       "    If `time` is included as an observation, the time in seconds\n",
       "    will be passed to the agent. This is the remainder time from \n",
       "    the beginning of the episode and for periods of the length\n",
       "    specified in the upper bound of the time feature. \n",
       "reward: list\n",
       "    List with string indicating the reward column name in a replay\n",
       "    buffer of data in case the algorithm is going to use pretraining\n",
       "max_episode_length: integer\n",
       "    Maximum duration of each episode in seconds\n",
       "random_start_time: boolean\n",
       "    Set to True if desired to use a random start time for each episode\n",
       "excluding_periods: list of tuples\n",
       "    List where each element is a tuple indicating the start and \n",
       "    end time of the periods that should not overlap with any \n",
       "    episode used for training. Example:\n",
       "    excluding_periods = [(31*24*3600,  31*24*3600+14*24*3600),\n",
       "                        (304*24*3600, 304*24*3600+14*24*3600)]\n",
       "    This is only used when `random_start_time=True`\n",
       "regressive_period: integer, default is None\n",
       "    Number of seconds for the regressive horizon. The observations\n",
       "    will be extended for each of the measurement variables indicated\n",
       "    in the `observations` dictionary argument. Specifically, a number \n",
       "    of `int(self.regressive_period/self.step_period)` observations per\n",
       "    measurement variable will be included in the observation space.\n",
       "    Each of these observations correspond to the past observation \n",
       "    of the measurement variable `j` steps ago. This is used in partially\n",
       "    observable MDPs to compensate for the hidden states. \n",
       "    Note that it is NOT allowed to use `regressive_period=0` since that\n",
       "    would represent a case where you want to include a measurement at\n",
       "    the current time in the observation space, which is directly done\n",
       "    when adding such measurement to the `observations` argument. \n",
       "predictive_period: integer, default is None\n",
       "    Number of seconds for the prediction horizon. The observations\n",
       "    will be extended for each of the predictive variables indicated\n",
       "    in the `observations` dictionary argument. Specifically, a number\n",
       "    of `int(self.predictive_period/self.step_period)` observations per \n",
       "    predictive variable will be included in the observation space.\n",
       "    Each of these observations correspond to the foresighted \n",
       "    variable `i` steps ahead from the actual observation time. \n",
       "    Note that it's allowed to use `predictive_period=0` when the\n",
       "    intention is to retrieve boundary condition data at the actual\n",
       "    observation time, useful e.g. for temperature setpoints or \n",
       "    ambient temperature. \n",
       "start_time: integer\n",
       "    Initial fixed episode time in seconds from beginning of the \n",
       "    year for each episode. Use in combination with \n",
       "    `random_start_time=False` \n",
       "warmup_period: integer\n",
       "    Desired simulation period to initialize each episode \n",
       "scenario: dictionary\n",
       "    Defines the BOPTEST scenario. Can be `constant`, `dynamic` or\n",
       "    `highly_dynamic`\n",
       "step_period: integer\n",
       "    Sampling time in seconds\n",
       "render_episodes: boolean\n",
       "    True to render every episode\n",
       "log_dir: string    \n",
       "    Directory to store results like plots or KPIs\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\irmak\\documents\\github\\rl_ex\\boptestgymservice\\boptestgymenv.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     BoptestGymEnvRewardClipping, BoptestGymEnvRewardWeightCost, BoptestGymEnvRewardWeightDiscomfort, BoptestGymEnvVariableEpisodeLength, BoptestGymEnvCustomReward"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BoptestGymEnv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ab01c1-e352-4fd3-9a45-942551e1f818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irmak\\anaconda3\\Lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "C:\\Users\\irmak\\anaconda3\\Lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = BoptestGymEnvCustomReward(url                   = url,\n",
    "                    testcase              = test_case,\n",
    "                    actions               = ['hvac_oveZonSupCor_TZonCooSet_u', \n",
    "                                             'hvac_oveZonSupEas_TZonCooSet_u', \n",
    "                                             'hvac_oveZonSupNor_TZonCooSet_u', \n",
    "                                             'hvac_oveZonSupWes_TZonCooSet_u',\n",
    "                                             'hvac_oveZonSupSou_TZonCooSet_u'],\n",
    "                    observations          = {\"hvac_reaZonCor_TZon_y\":(0, 35),\n",
    "                                             \"hvac_reaZonEas_TZon_y\":(0, 35),\n",
    "                                             \"hvac_reaZonWes_TZon_y\":(0, 35),\n",
    "                                             \"hvac_reaZonNor_TZon_y\":(0, 35),\n",
    "                                             \"hvac_reaZonSou_TZon_y\":(0, 35)},\n",
    "                    random_start_time     = False,\n",
    "                    start_time            = 31*24*3600,\n",
    "                    max_episode_length    = 24*3600,\n",
    "                    warmup_period         = 0,\n",
    "                    step_period           = 900,\n",
    "                    predictive_period     =10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b51756d5-59b9-480e-8754-7d7df001ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path =os.path.join(\"Training\", \"Boptest\", \"Logs\")\n",
    "TD3_path = os.path.join(\"Training\" , \"Saved Models\", \"TD3_Boptest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "789bbc1e-5017-48bd-886e-53714111411e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mTD3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtd3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTD3Policy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0menv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgymnasium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'VecEnv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbuffer_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_starts\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtau\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrain_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgradient_steps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maction_noise\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActionNoise\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreplay_buffer_class\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReplayBuffer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreplay_buffer_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moptimize_memory_usage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy_delay\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_policy_noise\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_noise_clip\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstats_window_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtensorboard_log\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Twin Delayed DDPG (TD3)\n",
       "Addressing Function Approximation Error in Actor-Critic Methods.\n",
       "\n",
       "Original implementation: https://github.com/sfujim/TD3\n",
       "Paper: https://arxiv.org/abs/1802.09477\n",
       "Introduction to TD3: https://spinningup.openai.com/en/latest/algorithms/td3.html\n",
       "\n",
       ":param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
       ":param env: The environment to learn from (if registered in Gym, can be str)\n",
       ":param learning_rate: learning rate for adam optimizer,\n",
       "    the same learning rate will be used for all networks (Q-Values, Actor and Value function)\n",
       "    it can be a function of the current progress remaining (from 1 to 0)\n",
       ":param buffer_size: size of the replay buffer\n",
       ":param learning_starts: how many steps of the model to collect transitions for before learning starts\n",
       ":param batch_size: Minibatch size for each gradient update\n",
       ":param tau: the soft update coefficient (\"Polyak update\", between 0 and 1)\n",
       ":param gamma: the discount factor\n",
       ":param train_freq: Update the model every ``train_freq`` steps. Alternatively pass a tuple of frequency and unit\n",
       "    like ``(5, \"step\")`` or ``(2, \"episode\")``.\n",
       ":param gradient_steps: How many gradient steps to do after each rollout (see ``train_freq``)\n",
       "    Set to ``-1`` means to do as many gradient steps as steps done in the environment\n",
       "    during the rollout.\n",
       ":param action_noise: the action noise type (None by default), this can help\n",
       "    for hard exploration problem. Cf common.noise for the different action noise type.\n",
       ":param replay_buffer_class: Replay buffer class to use (for instance ``HerReplayBuffer``).\n",
       "    If ``None``, it will be automatically selected.\n",
       ":param replay_buffer_kwargs: Keyword arguments to pass to the replay buffer on creation.\n",
       ":param optimize_memory_usage: Enable a memory efficient variant of the replay buffer\n",
       "    at a cost of more complexity.\n",
       "    See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n",
       ":param policy_delay: Policy and target networks will only be updated once every policy_delay steps\n",
       "    per training steps. The Q values will be updated policy_delay more often (update every training step).\n",
       ":param target_policy_noise: Standard deviation of Gaussian noise added to target policy\n",
       "    (smoothing noise)\n",
       ":param target_noise_clip: Limit for absolute value of target policy smoothing noise.\n",
       ":param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average\n",
       "    the reported success rate, mean episode length, and mean reward over\n",
       ":param tensorboard_log: the log location for tensorboard (if None, no logging)\n",
       ":param policy_kwargs: additional arguments to be passed to the policy on creation. See :ref:`td3_policies`\n",
       ":param verbose: Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for\n",
       "    debug messages\n",
       ":param seed: Seed for the pseudo random generators\n",
       ":param device: Device (cpu, cuda, ...) on which the code should be run.\n",
       "    Setting it to auto, the code will be run on the GPU if possible.\n",
       ":param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\irmak\\anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     DDPG"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TD3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46c85208-8a60-4412-b0f1-90c4a4c66e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = TD3('MlpPolicy', env, verbose = 1, tensorboard_log = log_path, learning_rate=0.001, gamma= 0.99, batch_size= 100, policy_delay=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45acd007-5dcf-4553-b9f4-abc6d9e7a910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Boptest\\Logs\\TD3_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96       |\n",
      "|    ep_rew_mean     | 59.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 0        |\n",
      "|    time_elapsed    | 769      |\n",
      "|    total_timesteps | 384      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 14.1     |\n",
      "|    critic_loss     | 0.443    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 283      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96       |\n",
      "|    ep_rew_mean     | 62.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 0        |\n",
      "|    time_elapsed    | 1479     |\n",
      "|    total_timesteps | 768      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 13.4     |\n",
      "|    critic_loss     | 0.555    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 667      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.td3.td3.TD3 at 0x154309dc2f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f099745e-02e8-4cc0-be3b-c8c51134f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(TD3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a413be51-f7bb-470e-a481-e4a77605c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irmak\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(65.0, 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f5edcc-4dc6-4021-b962-18fda62c1efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tdis_tot': 0,\n",
       " 'idis_tot': 0,\n",
       " 'ener_tot': 0,\n",
       " 'cost_tot': 0,\n",
       " 'emis_tot': 0,\n",
       " 'pele_tot': 4.720136809681116e-12,\n",
       " 'pgas_tot': None,\n",
       " 'pdih_tot': None,\n",
       " 'time_rat': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_kpis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603685df-4f56-429c-b025-805ff0ac0adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
