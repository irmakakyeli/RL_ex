{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3df72bb-fe1a-430e-a21f-cf0005e5f4ca",
   "metadata": {},
   "source": [
    "# This is a notebook of Reinforcement learning on Car pole problem with PPO and DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dde1c73-4092-4a42-95cd-3031f7d929b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extras] in c:\\users\\irmak\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extras]) (1.1.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extras]) (1.26.4)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extras]) (2.6.0+cu118)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extras]) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extras]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extras]) (3.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extras]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extras]) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extras]) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extras]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extras]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extras]) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extras]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extras]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extras]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extras]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extras]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extras]) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extras]) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3[extras]) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: stable-baselines3 2.6.0 does not provide the extra 'extras'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\irmak\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: swig in c:\\users\\irmak\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\irmak\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\irmak\\anaconda3\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\irmak\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extras]\n",
    "!pip install gymnasium\n",
    "!pip install swig\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda671d7-f116-458f-a649-28f43275d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eac3ff7-0d13-4a84-ad12-a95faf956ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627847d8-b4fe-403a-a3bc-067cca600959",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "env = gym.make(env_name, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b001242-70fc-4fc7-89a6-07e8aaf3575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1, Score:11.0\n",
      "Episode:2, Score:33.0\n",
      "Episode:3, Score:16.0\n",
      "Episode:4, Score:34.0\n",
      "Episode:5, Score:48.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Wrapper.close of <TimeLimit<OrderEnforcing<PassiveEnvChecker<CartPoleEnv<CartPole-v1>>>>>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range (1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{}, Score:{}\".format(episode, score))\n",
    "env.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186e43c-b0af-474a-9525-87802c5e0bee",
   "metadata": {},
   "source": [
    "Training, Logs and Saved Models files need to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eedf587-034a-4146-a69b-7190096339d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path =os.path.join(\"Training\", \"Logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a139b563-0bcb-43d0-8904-c863a601acec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mPPO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActorCriticPolicy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0menv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgymnasium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'VecEnv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0003\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_steps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_epochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgae_lambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclip_range\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclip_range_vf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNoneType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnormalize_advantage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0ment_coef\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvf_coef\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_sde\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msde_sample_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrollout_buffer_class\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRolloutBuffer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrollout_buffer_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_kl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstats_window_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtensorboard_log\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Proximal Policy Optimization algorithm (PPO) (clip version)\n",
       "\n",
       "Paper: https://arxiv.org/abs/1707.06347\n",
       "Code: This implementation borrows code from OpenAI Spinning Up (https://github.com/openai/spinningup/)\n",
       "https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n",
       "Stable Baselines (PPO2 from https://github.com/hill-a/stable-baselines)\n",
       "\n",
       "Introduction to PPO: https://spinningup.openai.com/en/latest/algorithms/ppo.html\n",
       "\n",
       ":param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
       ":param env: The environment to learn from (if registered in Gym, can be str)\n",
       ":param learning_rate: The learning rate, it can be a function\n",
       "    of the current progress remaining (from 1 to 0)\n",
       ":param n_steps: The number of steps to run for each environment per update\n",
       "    (i.e. rollout buffer size is n_steps * n_envs where n_envs is number of environment copies running in parallel)\n",
       "    NOTE: n_steps * n_envs must be greater than 1 (because of the advantage normalization)\n",
       "    See https://github.com/pytorch/pytorch/issues/29372\n",
       ":param batch_size: Minibatch size\n",
       ":param n_epochs: Number of epoch when optimizing the surrogate loss\n",
       ":param gamma: Discount factor\n",
       ":param gae_lambda: Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
       ":param clip_range: Clipping parameter, it can be a function of the current progress\n",
       "    remaining (from 1 to 0).\n",
       ":param clip_range_vf: Clipping parameter for the value function,\n",
       "    it can be a function of the current progress remaining (from 1 to 0).\n",
       "    This is a parameter specific to the OpenAI implementation. If None is passed (default),\n",
       "    no clipping will be done on the value function.\n",
       "    IMPORTANT: this clipping depends on the reward scaling.\n",
       ":param normalize_advantage: Whether to normalize or not the advantage\n",
       ":param ent_coef: Entropy coefficient for the loss calculation\n",
       ":param vf_coef: Value function coefficient for the loss calculation\n",
       ":param max_grad_norm: The maximum value for the gradient clipping\n",
       ":param use_sde: Whether to use generalized State Dependent Exploration (gSDE)\n",
       "    instead of action noise exploration (default: False)\n",
       ":param sde_sample_freq: Sample a new noise matrix every n steps when using gSDE\n",
       "    Default: -1 (only sample at the beginning of the rollout)\n",
       ":param rollout_buffer_class: Rollout buffer class to use. If ``None``, it will be automatically selected.\n",
       ":param rollout_buffer_kwargs: Keyword arguments to pass to the rollout buffer on creation\n",
       ":param target_kl: Limit the KL divergence between updates,\n",
       "    because the clipping is not enough to prevent large update\n",
       "    see issue #213 (cf https://github.com/hill-a/stable-baselines/issues/213)\n",
       "    By default, there is no limit on the kl div.\n",
       ":param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average\n",
       "    the reported success rate, mean episode length, and mean reward over\n",
       ":param tensorboard_log: the log location for tensorboard (if None, no logging)\n",
       ":param policy_kwargs: additional arguments to be passed to the policy on creation. See :ref:`ppo_policies`\n",
       ":param verbose: Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for\n",
       "    debug messages\n",
       ":param seed: Seed for the pseudo random generators\n",
       ":param device: Device (cpu, cuda, ...) on which the code should be run.\n",
       "    Setting it to auto, the code will be run on the GPU if possible.\n",
       ":param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\irmak\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PPO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0aa1b44-fb9c-4b19-9eee-1a761da6a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join(\"Training\" , \"Saved Models\", \"PPO_Modal_CartPole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052db110-6ea4-4828-9557-ed98a524a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=490, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=PPO_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34727eab-9559-49a4-821a-34bf75f24977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irmak\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name, render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log = log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8ab475-4093-47d6-ae79-5701129d6bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_6\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 46   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 43   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 45         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 90         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00783222 |\n",
      "|    clip_fraction        | 0.0839     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.687     |\n",
      "|    explained_variance   | 0.000858   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.22       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    value_loss           | 51.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009362311 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.0799      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 181          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068063834 |\n",
      "|    clip_fraction        | 0.0697       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irmak\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=318.80 +/- 124.21\n",
      "Episode length: 318.80 +/- 124.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 319         |\n",
      "|    mean_reward          | 319         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009024812 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 39    |\n",
      "|    iterations      | 5     |\n",
      "|    time_elapsed    | 259   |\n",
      "|    total_timesteps | 10240 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 40           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115476195 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.2         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    value_loss           | 62.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008898761 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 394          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026213827 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.94         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008855926 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011613362 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.551      |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 500.00  is above the threshold 490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x19828c216a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0804c7fb-5578-4101-a186-0e4c0bd83d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db75567-93f8-4d69-89a9-1fabe9e928c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd120b5-6ee1-44e0-b465-d333b2b08079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DummyVecEnv.close of <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000019828CDD610>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e99db71-daff-4209-bf7e-d4b6a188e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1, Score:[500.]\n",
      "Episode:2, Score:[500.]\n",
      "Episode:3, Score:[500.]\n",
      "Episode:4, Score:[500.]\n",
      "Episode:5, Score:[500.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DummyVecEnv.close of <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000019828CDD610>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range (1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{}, Score:{}\".format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b497aff9-9b6e-4a5d-9fe1-8959ec5efd5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\irmak\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8df3c-4998-4cf7-b29f-e76635b2fab2",
   "metadata": {},
   "source": [
    "## The following two line should be updated with each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffcf4e5e-4f67-4ba1-bd38-15e40e1afa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_p = os.path.join(log_path, \"PPO_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f400e98-4217-4c73-89a8-0b861bb9b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\\Logs\\PPO_6\n"
     ]
    }
   ],
   "source": [
    "print(training_log_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8255113e-8561-476c-8265-f4223b87ca83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b747b7bf99af70e7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b747b7bf99af70e7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./Training/Logs/PPO_6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63ee709e-2306-48e8-88af-1f2f7ec9324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
