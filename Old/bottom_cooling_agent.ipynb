{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab18b53-0928-443f-a404-3e5b20360a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\irmak\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.6.0+cu118)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.9.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.19.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.66.5)\n",
      "Requirement already satisfied: rich in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.7.1)\n",
      "Collecting shimmy~=0.2.1 (from shimmy[atari]~=0.2.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (10.4.0)\n",
      "Collecting autorom~=0.6.0 (from autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pygame in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: click in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from autorom~=0.6.0->autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from autorom~=0.6.0->autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra]) (2.32.3)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of shimmy[atari] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting gymnasium<1.3.0,>=0.29.1 (from stable-baselines3[extra])\n",
      "  Downloading gymnasium-1.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.10.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Downloading gymnasium-1.2.2-py3-none-any.whl (952 kB)\n",
      "   ---------------------------------------- 0.0/952.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 952.1/952.1 kB 22.3 MB/s eta 0:00:00\n",
      "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
      "Installing collected packages: gymnasium, stable-baselines3\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 0.28.1\n",
      "    Uninstalling gymnasium-0.28.1:\n",
      "      Successfully uninstalled gymnasium-0.28.1\n",
      "  Attempting uninstall: stable-baselines3\n",
      "    Found existing installation: stable-baselines3 2.0.0\n",
      "    Uninstalling stable-baselines3-2.0.0:\n",
      "      Successfully uninstalled stable-baselines3-2.0.0\n",
      "Successfully installed gymnasium-1.2.2 stable-baselines3-2.7.0\n",
      "Requirement already satisfied: tensorflow in c:\\users\\irmak\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\irmak\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]\n",
    "!pip install tensorflow\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1fd72b-cd01-4012-8536-716daec79781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mDQN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDQNPolicy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0menv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgymnasium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'VecEnv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbuffer_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_starts\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtau\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrain_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgradient_steps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreplay_buffer_class\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReplayBuffer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreplay_buffer_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moptimize_memory_usage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_steps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_update_interval\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexploration_fraction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexploration_initial_eps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexploration_final_eps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstats_window_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtensorboard_log\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Deep Q-Network (DQN)\n",
       "\n",
       "Paper: https://arxiv.org/abs/1312.5602, https://www.nature.com/articles/nature14236\n",
       "Default hyperparameters are taken from the Nature paper,\n",
       "except for the optimizer and learning rate that were taken from Stable Baselines defaults.\n",
       "\n",
       ":param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
       ":param env: The environment to learn from (if registered in Gym, can be str)\n",
       ":param learning_rate: The learning rate, it can be a function\n",
       "    of the current progress remaining (from 1 to 0)\n",
       ":param buffer_size: size of the replay buffer\n",
       ":param learning_starts: how many steps of the model to collect transitions for before learning starts\n",
       ":param batch_size: Minibatch size for each gradient update\n",
       ":param tau: the soft update coefficient (\"Polyak update\", between 0 and 1) default 1 for hard update\n",
       ":param gamma: the discount factor\n",
       ":param train_freq: Update the model every ``train_freq`` steps. Alternatively pass a tuple of frequency and unit\n",
       "    like ``(5, \"step\")`` or ``(2, \"episode\")``.\n",
       ":param gradient_steps: How many gradient steps to do after each rollout (see ``train_freq``)\n",
       "    Set to ``-1`` means to do as many gradient steps as steps done in the environment\n",
       "    during the rollout.\n",
       ":param replay_buffer_class: Replay buffer class to use (for instance ``HerReplayBuffer``).\n",
       "    If ``None``, it will be automatically selected.\n",
       ":param replay_buffer_kwargs: Keyword arguments to pass to the replay buffer on creation.\n",
       ":param optimize_memory_usage: Enable a memory efficient variant of the replay buffer\n",
       "    at a cost of more complexity.\n",
       "    See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n",
       ":param n_steps: When n_step > 1, uses n-step return (with the NStepReplayBuffer) when updating the Q-value network.\n",
       ":param target_update_interval: update the target network every ``target_update_interval``\n",
       "    environment steps.\n",
       ":param exploration_fraction: fraction of entire training period over which the exploration rate is reduced\n",
       ":param exploration_initial_eps: initial value of random action probability\n",
       ":param exploration_final_eps: final value of random action probability\n",
       ":param max_grad_norm: The maximum value for the gradient clipping\n",
       ":param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average\n",
       "    the reported success rate, mean episode length, and mean reward over\n",
       ":param tensorboard_log: the log location for tensorboard (if None, no logging)\n",
       ":param policy_kwargs: additional arguments to be passed to the policy on creation. See :ref:`dqn_policies`\n",
       ":param verbose: Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for\n",
       "    debug messages\n",
       ":param seed: Seed for the pseudo random generators\n",
       ":param device: Device (cpu, cuda, ...) on which the code should be run.\n",
       "    Setting it to auto, the code will be run on the GPU if possible.\n",
       ":param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\irmak\\anaconda3\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DQN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f55d1d-cd32-4479-ada5-9581fc05c093",
   "metadata": {},
   "source": [
    "try:\n",
    "  !rm -rf boptestGymService\n",
    "except:\n",
    "  pass\n",
    "!git clone -b boptest-gym-service https://github.com/ibpsa/project1-boptest-gym.git boptestGymService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc34e91-15b8-45a2-bda8-56b49143534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7beb85d8-902a-49ca-bea5-754ab2918d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'src/boptestGymService')\n",
    "\n",
    "url = 'http://localhost:80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f44b54-02f9-4bde-85d0-bf2407f849c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from boptestGymService.boptestGymEnv import BoptestGymEnv\n",
    "from boptestGymEnv import DiscretizedActionWrapper\n",
    "from gym.wrappers import FlattenObservation\n",
    "from boptestGymEnv import DiscretizedObservationWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92427732-c230-43fa-b9bf-4c3871394b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine reward function\n",
    "class BoptestGymEnvCustomReward(BoptestGymEnv):\n",
    "    def get_reward(self):\n",
    "        '''Custom reward function. We use the BOPTEST `GET /kpis` API call to compute the\n",
    "        total cummulative discomfort from the beginning of the episode. Note\n",
    "        that this is the true value that BOPTEST uses when evaluating\n",
    "        controllers.\n",
    "\n",
    "        'tdis_tot': temp discomfort\n",
    "         'idis_tot': 0,\n",
    "         'ener_tot': total energy\n",
    "         'cost_tot': total cost\n",
    "         'emis_tot': total emission\n",
    "         'pele_tot': defines the HVAC peak electrical demand.\n",
    "         'pgas_tot': defines the HVAC peak gas demand.\n",
    "         'pdih_tot': defines the HVAC peak district heating demand.\n",
    "         'time_rat': defines the average ratio between the controller computation time and the test simulation control step. The controller computation time is measured as the time between two emulator advances\n",
    "        '''\n",
    "        # Compute BOPTEST core kpis\n",
    "        kpis = requests.get('{0}/kpi/{1}'.format(self.url, self.testid)).json()['payload']\n",
    "        # Calculate objective integrand function as the total discomfort\n",
    "        objective_integrand = kpis['tdis_tot']\n",
    "        # Give reward if there is not immediate increment in discomfort\n",
    "        if objective_integrand == self.objective_integrand:\n",
    "          reward=1\n",
    "        else:\n",
    "          reward=0\n",
    "        # Record current objective integrand for next evaluation\n",
    "        self.objective_integrand = objective_integrand\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5eed2f-ea18-4051-9918-2d35c7d0b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case=\"multizone_office_simple_air\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f85ae6c-5d89-4e71-a31f-6bcb0b287b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mBoptestGymEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'http://127.0.0.1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtestcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bestest_hydronic_heat_pump'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'oveHeaPumY_u'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobservations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'reaTZon_y'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m280.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m310.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reward'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_episode_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_start_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexcluding_periods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mregressive_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpredictive_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstart_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarmup_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mscenario\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'electricity_price'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'constant'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstep_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrender_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:\\\\Users\\\\irmak\\\\Documents\\\\GitHub\\\\RL_ex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "BOPTEST Environment that follows gym interface.\n",
       "This environment allows the interaction of RL agents with building\n",
       "emulator models from BOPTEST. \n",
       " \n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "url: string\n",
       "    Rest API url for communication with the BOPTEST interface\n",
       "testcase: string\n",
       "    The string identifier of the testcase\n",
       "actions: list\n",
       "    List of strings indicating the action space. The bounds of \n",
       "    each variable from the action space the are retrieved from \n",
       "    the overwrite block attributes of the BOPTEST test case\n",
       "observations: dictionary\n",
       "    Dictionary mapping observation keys to a tuple with the lower\n",
       "    and upper bound of each observation. Observation keys must \n",
       "    belong either to the set of measurements or to the set of \n",
       "    forecasting variables of the BOPTEST test case. Contrary to \n",
       "    the actions, the expected minimum and maximum values of the \n",
       "    measurement and forecasting variables are not provided from \n",
       "    the BOPTEST framework, although they are still relevant here \n",
       "    e.g. for normalization or discretization. Therefore, these \n",
       "    bounds need to be provided by the user. \n",
       "    If `time` is included as an observation, the time in seconds\n",
       "    will be passed to the agent. This is the remainder time from \n",
       "    the beginning of the episode and for periods of the length\n",
       "    specified in the upper bound of the time feature. \n",
       "reward: list\n",
       "    List with string indicating the reward column name in a replay\n",
       "    buffer of data in case the algorithm is going to use pretraining\n",
       "max_episode_length: integer\n",
       "    Maximum duration of each episode in seconds\n",
       "random_start_time: boolean\n",
       "    Set to True if desired to use a random start time for each episode\n",
       "excluding_periods: list of tuples\n",
       "    List where each element is a tuple indicating the start and \n",
       "    end time of the periods that should not overlap with any \n",
       "    episode used for training. Example:\n",
       "    excluding_periods = [(31*24*3600,  31*24*3600+14*24*3600),\n",
       "                        (304*24*3600, 304*24*3600+14*24*3600)]\n",
       "    This is only used when `random_start_time=True`\n",
       "regressive_period: integer, default is None\n",
       "    Number of seconds for the regressive horizon. The observations\n",
       "    will be extended for each of the measurement variables indicated\n",
       "    in the `observations` dictionary argument. Specifically, a number \n",
       "    of `int(self.regressive_period/self.step_period)` observations per\n",
       "    measurement variable will be included in the observation space.\n",
       "    Each of these observations correspond to the past observation \n",
       "    of the measurement variable `j` steps ago. This is used in partially\n",
       "    observable MDPs to compensate for the hidden states. \n",
       "    Note that it is NOT allowed to use `regressive_period=0` since that\n",
       "    would represent a case where you want to include a measurement at\n",
       "    the current time in the observation space, which is directly done\n",
       "    when adding such measurement to the `observations` argument. \n",
       "predictive_period: integer, default is None\n",
       "    Number of seconds for the prediction horizon. The observations\n",
       "    will be extended for each of the predictive variables indicated\n",
       "    in the `observations` dictionary argument. Specifically, a number\n",
       "    of `int(self.predictive_period/self.step_period)` observations per \n",
       "    predictive variable will be included in the observation space.\n",
       "    Each of these observations correspond to the foresighted \n",
       "    variable `i` steps ahead from the actual observation time. \n",
       "    Note that it's allowed to use `predictive_period=0` when the\n",
       "    intention is to retrieve boundary condition data at the actual\n",
       "    observation time, useful e.g. for temperature setpoints or \n",
       "    ambient temperature. \n",
       "start_time: integer\n",
       "    Initial fixed episode time in seconds from beginning of the \n",
       "    year for each episode. Use in combination with \n",
       "    `random_start_time=False` \n",
       "warmup_period: integer\n",
       "    Desired simulation period to initialize each episode \n",
       "scenario: dictionary\n",
       "    Defines the BOPTEST scenario. Can be `constant`, `dynamic` or\n",
       "    `highly_dynamic`\n",
       "step_period: integer\n",
       "    Sampling time in seconds\n",
       "render_episodes: boolean\n",
       "    True to render every episode\n",
       "log_dir: string    \n",
       "    Directory to store results like plots or KPIs\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\irmak\\documents\\github\\rl_ex\\boptestgymservice\\boptestgymenv.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     BoptestGymEnvRewardClipping, BoptestGymEnvRewardWeightCost, BoptestGymEnvRewardWeightDiscomfort, BoptestGymEnvVariableEpisodeLength, BoptestGymEnvCustomReward"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BoptestGymEnv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ab01c1-e352-4fd3-9a45-942551e1f818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irmak\\anaconda3\\Lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "C:\\Users\\irmak\\anaconda3\\Lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "lower_setp = 21 + 273.15\n",
    "upper_setp = 24 + 273.15\n",
    "\n",
    "env = BoptestGymEnvCustomReward(url                   = url,\n",
    "                    testcase              = test_case,\n",
    "                    actions               = ['hvac_oveZonSupCor_TZonCooSet_u', \n",
    "                                             'hvac_oveZonSupNor_TZonCooSet_u',\n",
    "                                             'hvac_oveZonSupSou_TZonCooSet_u'],\n",
    "                    observations          = {\"hvac_reaZonCor_TZon_y\":(lower_setp, upper_setp),\n",
    "                                             \"hvac_reaZonNor_TZon_y\":(lower_setp, upper_setp),\n",
    "                                             \"hvac_reaZonSou_TZon_y\":(lower_setp, upper_setp)},\n",
    "                    random_start_time     = False,\n",
    "                    start_time            = 154*24*3600,\n",
    "                    max_episode_length    = 24*3600,\n",
    "                    warmup_period         = 24*3600,\n",
    "                    step_period           = 900,\n",
    "                    render_episodes= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "789bbc1e-5017-48bd-886e-53714111411e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_path = os.path.join( \"local_files\", \"Logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c85208-8a60-4412-b0f1-90c4a4c66e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = SAC('MlpPolicy', env, verbose=1, learning_rate=0.0003, gamma=0.99, batch_size=256, tensorboard_log= log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45acd007-5dcf-4553-b9f4-abc6d9e7a910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to src\\local_files\\Logs\\SAC_9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x171cd41e7b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b451dbd-fa8a-4fe4-9198-6e41cc37b77b",
   "metadata": {},
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14544267-8fac-4445-9785-542e77e9d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 29012), started 0:01:20 ago. (Use '!kill 29012' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5a49d4bab5c001fd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5a49d4bab5c001fd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./src/local_files/Logs/SAC_9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74e7a3c7-f1d7-4ae1-905a-b6cc6f38a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d809a8-8cc7-446f-8e3c-0a4f48e635d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15ad37-65f6-4f83-9109-a39a7f74e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    env = md.create_env(url, test_case, True)\n",
    "    model = SAC('MlpPolicy', env, verbose=1, learning_rate=0.0003, gamma=0.99, batch_size=256,\n",
    "                tensorboard_log=log_path)\n",
    "    SAC.load(\"SAC_model\", env = env)\n",
    "\n",
    "    done = False\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    from IPython.display import clear_output\n",
    "    while not done:\n",
    "        # Clear the display output at each step\n",
    "        #clear_output(wait=True)\n",
    "        # Compute control signal\n",
    "        action = model.predict(obs, deterministic=True)\n",
    "        # Print the current operative temperature and decided action\n",
    "        print('-------------------------------------------------------------------')\n",
    "        print('State  [Bin #]  = {:.0f}'.format(obs))\n",
    "        print('Action [ - ]    = {:.0f}'.format(action))\n",
    "        print('-------------------------------------------------------------------')\n",
    "        # Implement action\n",
    "        obs, reward, terminated, truncated, info = env.step(action)  # send the action to the environment\n",
    "        done = (terminated or truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03b4f9-9ee6-4fe5-a80e-e179c45e202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    env = md.create_env(url, test_case, True)\n",
    "    model = SAC('MlpPolicy', env, verbose=1, learning_rate=0.0003, gamma=0.99, batch_size=256,\n",
    "                tensorboard_log=log_path)\n",
    "    SAC.load(\"SAC_model\", env = env)\n",
    "\n",
    "    done = False\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    from IPython.display import clear_output\n",
    "    while not done:\n",
    "        # Clear the display output at each step\n",
    "        #clear_output(wait=True)\n",
    "        # Compute control signal\n",
    "        action = model.predict(obs, deterministic=True)\n",
    "        # Print the current operative temperature and decided action\n",
    "        print('-------------------------------------------------------------------')\n",
    "        print('State  [Bin #]  = {:.0f}'.format(obs))\n",
    "        print('Action [ - ]    = {:.0f}'.format(action))\n",
    "        print('-------------------------------------------------------------------')\n",
    "        # Implement action\n",
    "        obs, reward, terminated, truncated, info = env.step(action)  # send the action to the environment\n",
    "        done = (terminated or truncated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
